from dotenv import load_dotenv
from google.adk.agents import Agent
from google.adk.models.lite_llm import LiteLlm
from google.adk.tools.mcp_tool.mcp_toolset import (MCPToolset,
                                                   StdioServerParameters)

load_dotenv()


async def get_tools():
    """
    Initializes and establishes connection to the MCP Python server via Deno.

    Returns:
        tuple: A tuple containing:
            - tools (MCPToolset): Collection of MCP tools/commands for Python execution.
            - exit_stack (AsyncExitStack): Context manager for cleanup.
    """
    server_params = StdioServerParameters(
        command="deno",
        args=[
            "run",
            "-N",
            "-R=node_modules",
            "-W=node_modules",
            "--node-modules-dir=auto",
            "jsr:@pydantic/mcp-run-python",
            "stdio",
        ],
    )

    tools, exit_stack = await MCPToolset.from_server(connection_params=server_params)

    return tools, exit_stack


async def get_agent():
    """
    Initializes and returns the Python execution agent and its associated exit stack.

    Returns:
        tuple: A tuple containing:
            - root_agent (Agent): The configured Python agent.
            - exit_stack (AsyncExitStack): Context manager for cleanup.
    """
    tools, exit_stack = await get_tools()

    print(f"Successfully load {len(tools)} tools")

    root_agent = Agent(
        name="python_agent",
        model=LiteLlm("azure/gpt-4o-mini"),
        tools=tools,
        instruction="""You are an AI assistant capable of executing Python code.
        Use the available 'run_python' tool to execute Python code snippets provided by the user or generated by you to solve problems.
        Ensure the code is safe and relevant to the user's request.
        Present the execution results clearly.""",
    )

    return root_agent, exit_stack


root_agent = get_agent()
